{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lb5yiH5h8x3h"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMGdicu8PVD9"
      },
      "source": [
        "# Illustrating a book using Imagen 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR4Ti6Q0QKIl"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Book_illustration.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w14yjWnPVD-"
      },
      "source": [
        "In this guide, you are going to use multiple Gemini features (long context, multimodality, structured output, file API, chat mode...) in conjunction with the Imagen 3 model to illustrate a book.\n",
        "\n",
        "Each concept will be explained along the way, but if you need a simpler introduction to Imagen 3, check the [getting started](../quickstarts/Get_started_imagen.ipynb) notebook, or the [Imagen documentation](https://ai.google.dev/gemini-api/docs/imagen).\n",
        "\n",
        "Note: for the sake of the notebook's size (and your billing if you run it), the number of images has been limited to 3 characters and 3 chapters each time, but feel free to remove the limitation if you want more with your own experimentations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl0Hgj0rUv37"
      },
      "source": [
        "<!-- Princing warning Badge -->\n",
        "<table>\n",
        "  <tr>\n",
        "    <!-- Emoji -->\n",
        "    <td bgcolor=\"#f5949e\">\n",
        "      <font size=30>⚠️</font>\n",
        "    </td>\n",
        "    <!-- Text Content Cell -->\n",
        "    <td bgcolor=\"#f5949e\">\n",
        "      <h3><font color=black>Image generation is a paid-only feature and won't work if you are on the free tier. Check the <a href=\"https://ai.google.dev/pricing#imagen3\"><font color='#217bfe'>pricing</font></a> page for more details.</font></h3>\n",
        "    </td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0HWzIEAQYqz"
      },
      "source": [
        "## 0/ Setup\n",
        "\n",
        "This section install the SDK, set it up using your [API key](../quickstarts/Authentication.ipynb), imports the relevant libs, downloads the sample videos and upload them to Gemini.\n",
        "\n",
        "Just collapse (click on the little arrow on the left of the title) and run this section if you want to jump straight to the examples (just don't forget to run it otherwise nothing will work)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzBKAaL4QYq0"
      },
      "source": [
        "### Install SDK\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IbKkL5ksQYq1"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDUGen_kQYq2"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](../quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0H_lRdlrQYq3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Lez1vBQYq3"
      },
      "source": [
        "### Initialize SDK client\n",
        "\n",
        "With the new SDK you now only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://link_to_vertex_AI)). The model is now set in each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X3CAp9YrQYq4"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF5tDbb-Q0oc"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Some imports to display markdown text and images in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "B0Z9QzC3Q2wX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from PIL import Image\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjM1qLUGWF4l"
      },
      "source": [
        "### Select models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8vclK9GB_Rid"
      },
      "outputs": [],
      "source": [
        "imagen_model_name = \"imagen-3.0-generate-002\"  # @param [\"imagen-3.0-generate-002\"] {\"allow-input\":true, isTemplate: true}\n",
        "gemini_model_name = \"gemini-2.5-flash\"  # @param [\"gemini-2.5-flash-lite-preview-06-17\",\"gemini-2.5-flash\", \"gemini-2.5-flash\",\"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FnUZRfpMPda"
      },
      "source": [
        "For the sake of the notebook's size (and your billing if you run it), the number of images has been limited to 3 characters and 3 chapters each time, but feel free to remove the limitation if you want more with your own experimentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aX6YDaEqMP4O"
      },
      "outputs": [],
      "source": [
        "max_character_images = 3 # @param {type:\"integer\",isTemplate: true, min:1}\n",
        "max_chapter_images = 3 # @param {type:\"integer\",isTemplate: true, min:1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnID-boT_Kn7"
      },
      "source": [
        "# Illustrate a book: The Wind in the Willows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gDU5HFZLrF6"
      },
      "source": [
        "## 1/ Get a book and upload using the File API\n",
        "\n",
        "Start by downloading a book from the open-source [Project Gutenberg](www.gutenberg.org) library. For example, it can be [The Wind in the Willows](https://en.wikipedia.org/wiki/The_Wind_in_the_Willows) from Kenneth Grahame.\n",
        "\n",
        "`client.files.upload` is used to upload the file so that Gemini can easily access it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fqdyapDtVNFd"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/cache/epub/289/pg289.txt\"  # @param {type:\"string\"}\n",
        "\n",
        "response = requests.get(url)\n",
        "with open(\"book.txt\", \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "book = client.files.upload(file=\"book.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A48y6RTQg8in"
      },
      "source": [
        "## 2/ Start the chat\n",
        "\n",
        "You are going to use [chat mode](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#chat) here so that Gemini will keep the history of what you asked it, and also so that you don't have to send it the book every time. More details on chat mode in the [Get Started](https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started.ipynb#scrollTo=b6sB7W-jdGxJ) notebook.\n",
        "\n",
        "You should also define the format of the output you want using [structured output](https://ai.google.dev/gemini-api/docs/structured-output?lang=python#generate-json). You will mainly use Gemini to generate prompts so let's define a Pydantic model with two fields, a name and a prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Uu7g3OCVYwUk"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Prompts(BaseModel):\n",
        "    name: str\n",
        "    prompt: str\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-69Z7z9dKOV"
      },
      "source": [
        "`client.chats.create` starts the chat and defines its main parameters (model and the output you want)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rQa4Icv0XlCu"
      },
      "outputs": [],
      "source": [
        "# Re-run this cell if you want to start anew.\n",
        "chat = client.chats.create(\n",
        "    model=gemini_model_name,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[Prompts],\n",
        "    ),\n",
        ")\n",
        "\n",
        "chat.send_message(\n",
        "    [\n",
        "        \"Here's a book, to illustrate using Imagen. Don't say anything for now, instructions will follow.\",\n",
        "        book\n",
        "    ]\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3WSN7OOdW3p"
      },
      "source": [
        "The first message sent to the model is just to give it a bit of context (\"*to illustrate using Imagen*\"), and more importantly give it the book.\n",
        "\n",
        "It could have been done during the next step, especially since you're not interested in what the model has to say this time, but splitting the two steps makes it clearer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNsJ0BgbhA-4"
      },
      "source": [
        "## 3/ Define a style\n",
        "\n",
        "If you want to test a specific style, just write it down and Gemini will use it. Still, tell Gemini about it so it will adapt the prompts it will generate accordingly.\n",
        "\n",
        "If you prefer to let Gemini choose the best style for the book, leave the style empty and ask Gemini to define a style fitting to the book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vASY44jBdP4o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "c716cbbc-fbae-48d0-e911-5ad33a90b44c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Style:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classic whimsical children's book illustration, rendered in soft watercolours and gentle ink lines, with warm, dreamy lighting and charming pastoral details.\n"
          ]
        }
      ],
      "source": [
        "style = \"\" # @param {type:\"string\", \"placeholder\":\"Write your own style or leave empty to let Gemini generate one\"}\n",
        "\n",
        "if style==\"\":\n",
        "  response = chat.send_message(\"\"\"\n",
        "    Can you define a art style that would fit the story?\n",
        "    Just give us the prompt for the art syle that will added to the furture prompts.\n",
        "    \"\"\")\n",
        "  style = json.loads(response.text)[0][\"prompt\"]\n",
        "else:\n",
        "  chat.send_message(f\"\"\"\n",
        "    The art style will be:\"{style}\".\n",
        "    Keep that in mind when generating future prompts.\n",
        "    Keep quiet for now, instructions will follow.\n",
        "  \"\"\")\n",
        "\n",
        "display(Markdown(f\"### Style:\"))\n",
        "print(style)\n",
        "\n",
        "style = f'Follow this style: \"{style}\" '"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHjcGgtoadjB"
      },
      "source": [
        "Let's also define some more instructions which will act as \"system instructions\" or a negative prompt to tell the model what you do not want to see (text on the images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gdFWhMCXbfpd"
      },
      "outputs": [],
      "source": [
        "system_instructions = \"\"\"\n",
        "  There must be no text on the image, it should not look like a cover page.\n",
        "  It should be an full illustration with no borders, titles, nor description.\n",
        "  Stay family-friendly with uplifting colors.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp1vK2f0hEig"
      },
      "source": [
        "## 4/ Generate portraits of the main characters\n",
        "\n",
        "You are now ready to start generating images, starting with the main characters.\n",
        "\n",
        "Ask Gemini to describe each of the main characters (excluding children as Imagen can't generate images of them) and check that the output follows the format requested.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f1Gfpp9xYlXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069b005c-eb7f-4564-ef76-956bce70c094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"Mole Character Prompt\",\n",
            "        \"prompt\": \"A small, good-hearted Mole with short legs and dark fur, sometimes splattered with whitewash. He has a simple, somewhat timid nature but can be impatient and surprisingly confident in new experiences. He often finds himself overwhelmed by new sights and emotions, prone to both rapture and 'squashy, pulpy misery.' He is loyal and appreciative of home comforts, learning to navigate the wider world beyond his underground dwelling.\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Water Rat Character Prompt\",\n",
            "        \"prompt\": \"A dapper, good-natured Water Rat with a brown, grave, and round face, notable for its twinkling eyes, small neat ears, and thick silky hair. He is deeply devoted to his river and boat, often speaking dreamily and solemnly about 'messing about in boats.' Practical and perceptive, he can be stern when necessary and is fiercely loyal to his friends, often taking a protective stance, even carrying pistols and a cudgel when venturing into the Wild Wood.\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Badger Character Prompt\",\n",
            "        \"prompt\": \"A formidable, solitary grey Badger, gruff and reclusive, yet possessing a deep kindness and paternal understanding towards his friends. He is rarely seen in society, preferring his warm, expansive underground home with its well-worn red brick kitchen and rustic comforts. He often wears a long dressing-gown and down-at-heel slippers. Despite his shyness, he is a wise, steadfast figure whose bristling whiskers and great cudgel signify his readiness to defend his friends when provoked.\"\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Toad Character Prompt\",\n",
            "        \"prompt\": \"A short, stout Toad with an extremely volatile and self-absorbed personality, oscillating between boisterous excitement and profound despair. He has a powerful imagination and a tendency towards boastfulness and conceit, especially concerning his latest fads like motorcars, for which he dresses in 'singularly hideous habiliments.' Despite his self-centeredness and frequent misadventures, he is fundamentally good-tempered, affectionate, and capable of both a 'blustering spirit' and genuine, albeit temporary, repentance.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"\"\"\n",
        "  Can you describe the main characters (only the adults) and\n",
        "  prepare a prompt describing them with as much details as possible (use the descriptions from the book)\n",
        "  so Imagen can generate images of them? Each prompt should be at least 50 words.\n",
        "\"\"\")\n",
        "\n",
        "characters = json.loads(response.text)\n",
        "\n",
        "print(json.dumps(characters, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smw57Slmhh7v"
      },
      "source": [
        "Now that you have the prompts, you just need to loop on all the characters and have Imagen generate an image for them. This is done using `client.models.generate_images`.\n",
        "\n",
        "For an extensive explanation on the Imagen model and the `generate_images` options, check the [getting started with Imagen](../quickstarts/get_started_imagen.ipynb) notebook. But here's a quick overview of what being used here:\n",
        "* `prompt` is the prompt passed down to Imagen. You're not just sending what Gemini has generate to describe the chacaters but also our style and our system instructions.\n",
        "* you only need one image, so `number_of_images` is set to 1\n",
        "* `safety_filter_level` is set to the higher level because the images needs to be family friendly\n",
        "* `person_generation` is disable since none of the characters are people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-xrgPhzCbGhq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "9a85fb11-21df-4923-884d-2bd96899ab08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Mole Character Prompt"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "A small, good-hearted Mole with short legs and dark fur, sometimes splattered with whitewash. He has a simple, somewhat timid nature but can be impatient and surprisingly confident in new experiences. He often finds himself overwhelmed by new sights and emotions, prone to both rapture and 'squashy, pulpy misery.' He is loyal and appreciative of home comforts, learning to navigate the wider world beyond his underground dwelling."
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Imagen API is only accessible to billed users at this time.', 'status': 'INVALID_ARGUMENT'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2512430928>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   image_generated = client.models.generate_images(\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimagen_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharacter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msystem_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_images\u001b[0;34m(self, model, prompt, config)\u001b[0m\n\u001b[1;32m   6295\u001b[0m       \u001b[0;31m# Shows a man with a dog.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m     \"\"\"\n\u001b[0;32m-> 6297\u001b[0;31m     api_response = self._generate_images(\n\u001b[0m\u001b[1;32m   6298\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6299\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_images\u001b[0;34m(self, model, prompt, config)\u001b[0m\n\u001b[1;32m   5247\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5249\u001b[0;31m     response_dict = self._api_client.request(\n\u001b[0m\u001b[1;32m   5250\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5251\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mhttp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     )\n\u001b[0;32m--> 927\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    791\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m       )\n\u001b[0;32m--> 793\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m       return HttpResponse(\n\u001b[1;32m    795\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': 'Imagen API is only accessible to billed users at this time.', 'status': 'INVALID_ARGUMENT'}}"
          ]
        }
      ],
      "source": [
        "for character in characters[:max_character_images]:\n",
        "  display(Markdown(f\"### {character['name']}\"))\n",
        "  display(Markdown(character['prompt']))\n",
        "\n",
        "  image_generated = client.models.generate_images(\n",
        "      model=imagen_model_name,\n",
        "      prompt=character['prompt'] + style + system_instructions,\n",
        "      config=types.GenerateImagesConfig(\n",
        "          number_of_images=1,\n",
        "          safety_filter_level=\"BLOCK_LOW_AND_ABOVE\",\n",
        "          person_generation=\"ALLOW_ADULT\",\n",
        "          aspect_ratio=\"9:16\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  if image_generated.generated_images is not None:\n",
        "    for generated_image in image_generated.generated_images:\n",
        "      generated_image.image.show()\n",
        "\n",
        "# Be careful; long output (see below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLYE7NJK-f6t"
      },
      "source": [
        "The output of the previous code cell could not be saved in the notebook without making it too big to be managed by Github, but here's what it should look like when you run it:\n",
        "\n",
        "-----------\n",
        "**Badger Prompt**  \n",
        "Illustration of Badger, wearing a long dressing-gown and down-at-heel slippers, carrying a flat candlestick. He has a long snout, sleepy blinking eyes and a grave expression. The badger is kind but stern, with visible wrinkles. He has stout oaken, comfortable-looking doors in his underground home and is holding a sturdy wooden walking stick. He is old, and very tired from walking far, but has very sharp claws. His dressing gown should be a dark, earthy tone and have a simple but practical design with a large red cotton handkerchief.\n",
        "\n",
        "![Generated image of the 1st character](https://storage.googleapis.com/generativeai-downloads/images/character1.png)\n",
        "\n",
        "**Water Rat Prompt**  \n",
        "Illustration of Water Rat, well-groomed and neat. Wearing a black velvet smoking-suit, clean and pressed, but slightly worn from extensive river activity, and a boater hat. His neat ears and thick silky hair are visible. He is jovial but serious, holding a pair of sculls. His fur is sleek and well-maintained, reflecting his connection to the river, and has river shop and is always wanting you to do something as if a fellow had no business of his own to attend to. The background is lush riverbank.\n",
        "\n",
        "![Generated image of the 2nd character](https://storage.googleapis.com/generativeai-downloads/images/character2.png)\n",
        "\n",
        "**Toad Prompt**  \n",
        "Illustration of Toad, Boastful and conceited. He is short and stout, and often wears flamboyant clothing and is about to order a motor-car from a townsperson who is showing him a poster. This is a new craze, and he always takes him that way. He has a placid satisfied expression and at intervals he faintly murmurs “Poop-poop!”. The scene will take place near a building showing motorcar advertisements.\n",
        "\n",
        "![Generated image of the 3rd character](https://storage.googleapis.com/generativeai-downloads/images/character3.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7FrgFJEhKEM"
      },
      "source": [
        "## 5/ Illustrate the chapters of the book\n",
        "\n",
        "After the characters, it's now time to create illustrations for the content of the book. You are going to ask Gemini to generate prompts for each chapter and then ask Imagen to generate images based on those prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSq9XajOfOZI"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Now, for each chapters of the book, give me a prompt to illustrate what happens in it. Be very descriptive, especially of the characters. Be very descriptive and remember to reuse the character prompts if they appear in the images. Each character should at least be described with 30 words.\")\n",
        "\n",
        "chapters = json.loads(response.text)[:max_chapter_images]\n",
        "\n",
        "print(json.dumps(chapters, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCKeNunagDQU"
      },
      "outputs": [],
      "source": [
        "for chapter in chapters:\n",
        "  display(Markdown(f\"### {chapter['name']}\"))\n",
        "  display(Markdown(chapter['prompt']))\n",
        "\n",
        "  image_generated = client.models.generate_images(\n",
        "      model=imagen_model_name,\n",
        "      prompt=chapter['prompt'] + style + system_instructions,\n",
        "      config=types.GenerateImagesConfig(\n",
        "          number_of_images=1,\n",
        "          output_mime_type=\"image/jpeg\",\n",
        "          safety_filter_level=\"BLOCK_LOW_AND_ABOVE\",\n",
        "          person_generation=\"ALLOW_ADULT\",\n",
        "          aspect_ratio=\"1:1\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  if image_generated.generated_images is not None:\n",
        "    for generated_image in image_generated.generated_images:\n",
        "      generated_image.image.show()\n",
        "\n",
        "# Be careful, long output (see below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuGCT3K9_-aS"
      },
      "source": [
        "The output of the previous code cell could not be saved in the notebook without making it too big to be managed by Github, but here's what it should look like when you run it:\n",
        "\n",
        "-----------\n",
        "**Chapter I Prompt**  \n",
        "Illustration of Mole, a small, black-furred animal with splashes of whitewash all over him, working busily with brooms and brushes in his dark, lowly little house, preparing for spring cleaning. Rat, well-groomed and neat in his black velvet smoking-suit, is sculling in his blue and white boat, casually dressed and leisurely enjoying the river. The full-fed river itself, a sleek, sinuous, full-bodied animal, reflects the warm sunlight and happy birds, and the riverbank is lush and green. Mole looks up and see's Rat for the first time, a grave brown round face, with the same twinkle in its eye that had first attracted his notice.\n",
        "\n",
        "![Generated image of the 1st chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter1.png)\n",
        "\n",
        "\n",
        "**Chapter II Prompt**  \n",
        "Illustration of Rat, cheerful in his boater hat, dismissing poetry from his mind as he jumps to his feet. Mole is shorter with his head a little bit down wearing a black velvet smoking-suit. They are on their way to call on Mr. Toad, whose house is dignified old house of mellowed red brick, with well-kept lawns. Toad is resting in a wicker garden-chair, with a pre-occupied expression and a large map. Hooray!” he cried, jumping up on seeing them. This is a sunny summer morning.\n",
        "\n",
        "![Generated image of the 2nd chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter2.png)\n",
        "\n",
        "\n",
        "**Chapter III Prompt\n",
        "Illustration of Mole, small and dark furred, alone and increasingly frightened in the Wild Wood in Winter. Wicked faces pop out of holes around him, while wind whistles shrilly through the leafless trees and pattering footsteps come ever closer. He is running clumsily through the snow, trying to find a safe place to hide. Warm and comfortable Rat is inside dozing and alternating dozing and trying over rhymes that wouldn’t fit.\n",
        "\n",
        "![Generated image of the 3rd chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter3.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU1GVuZvhO9g"
      },
      "source": [
        "# With an Audiobook: The Adventures of Chatterer the Red Squirrel\n",
        "\n",
        "This time, you are going to use an audiobook as the source, and in this case *The Adventures of Chatterer the Red Squirrel* audiobook from the open-source library [Librivox](https://librivox.org/the-adventures-of-chatterer-the-red-squirel-by-thornton-w-burgess/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiRA6hC3-noh"
      },
      "source": [
        "## 1/ Get the audiobook and merge its chapters\n",
        "You could upload all the chapters one by one, but it's easier to merge all the chapters together befor uploading the audiobook and only deal with one file.\n",
        "\n",
        "For the sake of the length of the demonstration, you will only merge the first 5 chapters, but feel free to update the code and try on the full book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGSQv5YnhQpD"
      },
      "outputs": [],
      "source": [
        "%pip install pydub\n",
        "import os\n",
        "import zipfile\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Download the zip file\n",
        "!wget https://www.archive.org/download/chatterertheredsquirrel_1307_librivox/chatterertheredsquirrel_1307_librivox_64kb_mp3.zip\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(\"chatterertheredsquirrel_1307_librivox_64kb_mp3.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"audiobook\")\n",
        "\n",
        "# Get a list of all MP3 files in the extracted folder\n",
        "mp3_files = [f for f in os.listdir(\"audiobook\") if f.endswith('.mp3')]\n",
        "\n",
        "mp3_files.sort()\n",
        "\n",
        "if len(mp3_files) > 1:\n",
        "    combined_audio = AudioSegment.empty()\n",
        "    for i in range(min(5, len(mp3_files))):  # Limit to 5 or fewer chapters\n",
        "        mp3_file = mp3_files[i]  # Get the filename using the index\n",
        "        combined_audio += AudioSegment.from_mp3(os.path.join(\"audiobook\", mp3_file))\n",
        "    combined_audio.export(\"audiobook.mp3\", format=\"mp3\")\n",
        "    print(\"MP3 files merged into audiobook.mp3\")\n",
        "else:\n",
        "    print(\"Only one MP3 file found, no merging needed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU0MeGrMgDLn"
      },
      "source": [
        "Now upload it using the File API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9SUqnFZioK8"
      },
      "outputs": [],
      "source": [
        "audiobook = client.files.upload(file=\"audiobook.mp3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV5Cscn0iYxF"
      },
      "source": [
        "## 2/ Start the chat\n",
        "\n",
        "Oonce again, using [chat mode](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#chat) here let Gemini will keep the history of what you asked it, and also so that you don't have to send it the book every time.\n",
        "\n",
        "[Structured output](https://ai.google.dev/gemini-api/docs/structured-output?lang=python#generate-json) is used to force Gemini to output nice lists of prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tmfdTAniYxD"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Prompts(BaseModel):\n",
        "    name: str\n",
        "    prompt: str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLXjNQFIiYxG"
      },
      "outputs": [],
      "source": [
        "# Re-run this cell if you want to start anew.\n",
        "chat = client.chats.create(\n",
        "    model=gemini_model_name,\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=list[Prompts],\n",
        "    ),\n",
        ")\n",
        "\n",
        "chat.send_message([\"Here's an audiobook, to illustrate using Imagen. Don't say anything for now, instructions will follow.\",audiobook]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-PBK3CfiYxG"
      },
      "source": [
        "## 3/ Define a style\n",
        "\n",
        "If you want to test a specific style, just write it down and Gemini will use it. Still, tell Gemini about it so it will adapt the prompts it will generate accordingly. That's what is illustrated here with a futuristic style.\n",
        "\n",
        "If you prefer to let Gemini choose the best style for the book, leave the style empty and ask Gemini to define a style fitting to the book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZyCq43HiYxG"
      },
      "outputs": [],
      "source": [
        "style = \"futuristic, science fiction, utopia, saturated, neon lights\" # @param {type:\"string\", \"placeholder\":\"Write your own style or leave empty to let Gemini generate one\"}\n",
        "\n",
        "if style == \"\":\n",
        "  response = chat.send_message(\"Can you define a art style that would fit the story? Just give us the prompt for the art syle that will added to the furture prompts.\")\n",
        "  style = json.loads(response.text)[0][\"prompt\"]\n",
        "else:\n",
        "  chat.send_message(f'The art style will be:\"{style}\". Keep that in mind when generating future prompts. Keep quiet for now, instructions will follow.')\n",
        "\n",
        "display(Markdown(f\"### Style:\"))\n",
        "print(style)\n",
        "\n",
        "style = f'Follow this style: \"{style}\" '"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoJiVPgagiSJ"
      },
      "outputs": [],
      "source": [
        "system_instructions = \"\"\"\n",
        "  There must be no text on the image, it should not look like a cover page.\n",
        "  It should be an full illustration with no borders, titles, nor description.\n",
        "  Stay family-friendly with uplifting colors.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIWMLd0AiYxH"
      },
      "source": [
        "## 4/ Generate portraits of the main characters\n",
        "\n",
        "You are now ready to start generating images, starting with the main characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XW4jpNaiYxH"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message([\"Can you describe the main characters and prepare a prompt describing them with as much details as possible (use the descriptions from the book) so Imagen can generate images of them?\"])\n",
        "\n",
        "characters = json.loads(response.text)\n",
        "\n",
        "print(json.dumps(characters, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlkGgaudiYxI"
      },
      "outputs": [],
      "source": [
        "for character in characters[:max_character_images]:\n",
        "  display(Markdown(f\"### {character['name']}\"))\n",
        "  display(Markdown(character['prompt']))\n",
        "\n",
        "  image_generated = client.models.generate_images(\n",
        "      model=imagen_model_name,\n",
        "      prompt=character['prompt'] + style + system_instructions,\n",
        "      config=types.GenerateImagesConfig(\n",
        "          number_of_images=1,\n",
        "          output_mime_type=\"image/jpeg\",\n",
        "          safety_filter_level=\"BLOCK_LOW_AND_ABOVE\",\n",
        "          person_generation=\"ALLOW_ADULT\",\n",
        "          aspect_ratio=\"9:16\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  if image_generated.generated_images is not None:\n",
        "    for generated_image in image_generated.generated_images:\n",
        "      generated_image.image.show()\n",
        "\n",
        "# Be careful, long output (see below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4wERhCpBVst"
      },
      "source": [
        "The output of the previous code cell could not be saved in the notebook without making it too big to be managed by Github, but here's what it should look like when you run it:\n",
        "\n",
        "-----------\n",
        "\n",
        "**Chatterer the Red Squirrel Description**  \n",
        "Create a futuristic, science fiction image of Chatterer the Red Squirrel: a small, agile squirrel with bright red, almost neon, fur. His eyes are beady and full of mischief, glowing with a faint light. He has a long, bushy tail, augmented with cybernetic enhancements, which he uses for balance and expression. He is always alert and energetic, constantly chattering and scampering about on technologically advanced trees, fitted with utopia components.\n",
        "\n",
        "![Generated image of the 1st character](https://storage.googleapis.com/generativeai-downloads/images/character1_audio.png)\n",
        "\n",
        "\n",
        "**Shadow the Weasel Description**  \n",
        "Create a futuristic, science fiction image of Shadow the Weasel: a sleek and sinister weasel with a long, slender body and short legs, enhanced with subtle cybernetics for increased speed. His fur is a dark, shadowy color, almost absorbing light, and his eyes are beady and cunning, with a menacing red glow. He moves with a silent grace, often accompanied by faint neon trails, always lurking in the shadows of a technologically advanced environment, and waiting for his opportunity to strike.\n",
        "\n",
        "![Generated image of the 2nd character](https://storage.googleapis.com/generativeai-downloads/images/character2_audio.png)\n",
        "\n",
        "\n",
        "**Peter Rabbit Description**  \n",
        "Create a futuristic, science fiction image of Peter Rabbit: a small and cautious rabbit with soft, brown fur, augmented with sensory enhancements, and long, floppy ears tipped with neon lights. His eyes are wide and innocent, but possess an augmented, digital overlay displaying threat assessment data. He always seems to be on the lookout for danger, relying on enhanced senses and agility to escape from trouble in a utopia inspired landscape.\n",
        "\n",
        "![Generated image of the 3rd character](https://storage.googleapis.com/generativeai-downloads/images/character3_audio.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMMLutf0iYxI"
      },
      "source": [
        "## 5/ Illustrate the chapters of the book\n",
        "\n",
        "After the characters, it's now time to create illustrations for the content of the book. You are going to ask Gemini to generate prompts for each chapter and then ask Imagen to generate images based on those prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsQY1vY4iYxJ"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message([\"Now, for each chapter of the book, give me a prompt to illustrate what happens in it. Be very descriptive, especially of the characters. Remember to reuse the character prompts if they appear in the image\"])\n",
        "\n",
        "chapters = json.loads(response.text)[:max_chapter_images]\n",
        "\n",
        "print(json.dumps(chapters, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjhcPwV-iYxJ"
      },
      "outputs": [],
      "source": [
        "for chapter in chapters:\n",
        "  display(Markdown(f\"### {chapter['name']}\"))\n",
        "  display(Markdown(chapter['prompt']))\n",
        "\n",
        "  image_generated = client.models.generate_images(\n",
        "      model=imagen_model_name,\n",
        "      prompt=chapter['prompt'] + style + system_instructions,\n",
        "      config=types.GenerateImagesConfig(\n",
        "          number_of_images=1,\n",
        "          output_mime_type=\"image/jpeg\",\n",
        "          safety_filter_level=\"BLOCK_LOW_AND_ABOVE\",\n",
        "          person_generation=\"ALLOW_ADULT\",\n",
        "          aspect_ratio=\"1:1\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "  for generated_image in image_generated.generated_images:\n",
        "    image = generated_image.image.show()\n",
        "\n",
        "  # Be careful, long output (see below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IUmX4CDBYvH"
      },
      "source": [
        "The output of the previous code cell could not be saved in the notebook without making it too big to be managed by Github, but here's what it should look like when you run it:\n",
        "\n",
        "-----------\n",
        "\n",
        "**Chapter 1 Illustration Prompt**  \n",
        "Create a futuristic, science fiction image of Chatterer the Red Squirrel running for his life through a forest filled with neon-lit, bioluminescent plants and towering, chrome trees. The forest floor is a mosaic of holographic projections, creating a surreal, dreamlike atmosphere. Utopia, saturated art style. Shadow the Weasel is in hot pursuit, his cybernetic eyes glowing with predatory hunger, leaving a faint neon trail that distorts the air. Chatterer, small and terrified, augmented with a speed booster that leaves a shimmering afterimage, leaps desperately from tree to tree, his bright red, neon-infused fur a blur against the vibrant background. Imagine the scene filled with a pounding synthwave soundtrack, with a sense of urgency and danger permeating the scene, emphasizing Chatterer's vulnerability and Shadow's relentless pursuit.\n",
        "\n",
        "![Generated image of the 1st chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter1_audio.png)\n",
        "\n",
        "**Chapter 2 Illustration Prompt**  \n",
        "Create a futuristic, science fiction image of Chatterer the Red Squirrel scrambling up a towering, genetically-modified chestnut tree that spirals upwards, supported by visible energy conduits, toward Red Tail the Hawk, who is dozing on a high-tech perch made of polished chrome, head tucked between his cybernetically enhanced shoulders. Utopia, saturated art style. Chatterer's augmented eyes are wide with a daring plan, calculating angles and trajectories, as Shadow the Weasel follows close behind, his movements leaving subtle distortions in the air and glitching holographic leaves. The scene should be a mix of tension and vibrant color, capturing the risk and ingenuity of Chatterer's actions, with neon accents illuminating the genetically-altered foliage and emphasizing the futuristic setting. Glimpses of advanced technology can be seen embedded within the tree's structure.\n",
        "\n",
        "![Generated image of the 2nd chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter2_audio.png)\n",
        "\n",
        "Chapter 3 Illustration Prompt\n",
        "Create a futuristic, science fiction image of Chatterer the Red Squirrel urgently telling Sammy Jay about Shadow the Weasel, their figures illuminated by glowing data streams. Utopia, saturated art style. Sammy Jay listens with wide, attentive eyes, augmented with holographic displays that project potential threats, perched on a branch of a tree constructed from shimmering, nanotech materials that seem to shift and change color. The lighting is vibrant, emphasizing the important news being shared, with a technologically advanced forest in the background hinting at the scale of Chatterer's warning. Holographic butterflies, acting as data couriers, flutter around Sammy as he processes the news, their wings leaving trails of light.\n",
        "\n",
        "![Generated image of the 3rd chapter](https://storage.googleapis.com/generativeai-downloads/images/chapter3_audio.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFl3Hlc8NPdr"
      },
      "source": [
        "# Next Steps\n",
        "### Useful documentation references:\n",
        "\n",
        "To improve your prompting skills, check the [prompt guide](https://ai.google.dev/gemini-api/docs/imagen-prompt-guide) for great advices on creating your prompts.\n",
        "\n",
        "### Related examples\n",
        "\n",
        "If you're curious about cool things you can build with Imagen, check those great examples:\n",
        "* [Zoom on earth](../examples/Zoom_on_earth.ipynb): Another take on mixing Gemini and Imagen, this time using [function calling](./Function_calling.ipynb) to communicate.\n",
        "* [Generative designs](../examples/Generative_designs.ipynb): This time Gemini will ingest a bunch of images to serve as models to generate model designs.\n",
        "\n",
        "### Continue your discovery of the Gemini API\n",
        "\n",
        "Gemini is not only good at generating images, but also at understanding them. Check the [Spatial understanding](./Spatial_understanding.ipynb) guide for an introduction on those capabilities, and the [Video understanding](./Video_understanding.ipynb) one for video examples.\n",
        "\n",
        "You should also have a look at the [Live API](../quickstarts/Get_started_LiveAPI.ipynb) to create live intereactions with the models.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lb5yiH5h8x3h"
      ],
      "name": "Book_illustration.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}